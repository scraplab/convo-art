{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/f004swn/anaconda3/envs/scrap_hack/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import whisper\n",
    "from transcriber import transcribe\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "#RATE = 44100\n",
    "RATE = 16000\n",
    "CHUNK = 16000\n",
    "THRESHOLD = 1500  # Adjust this value based on your microphone and environment\n",
    "AUDIOFILE_PATH = '/Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAP = 2 # Length of silence allowed before cut\n",
    "SESSION_TIME = 3 # number of mins the session can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the Scarlett\n",
    "devices = []\n",
    "device_index = None\n",
    "for i in range(p.get_device_count()):\n",
    "    device_info = p.get_device_info_by_index(i)\n",
    "    devices.append(device_info)\n",
    "    if \"Scarlett\" in device_info[\"name\"] and device_info[\"maxInputChannels\"] > 0:\n",
    "        device_index = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for speech...\n"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for speech...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = p.open(input_device_index=device_index,\n",
    "                format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordTranscribe(threading.Thread):\n",
    "    def __init__(self, rms):\n",
    "        super().__init__()\n",
    "        self.is_recording = True\n",
    "        self.is_transcribing = False\n",
    "        self.is_writing = False\n",
    "        self.rms = rms\n",
    "        self.text = None\n",
    "        self.start_time = None\n",
    "        self.stop_time = None\n",
    "        self.frames = []\n",
    "        self.data = None\n",
    "        self.completed = False\n",
    "        \n",
    "    def record(self):\n",
    "        self.start_time = time.time()\n",
    "        print(f\"{self._name} starts recording...\")\n",
    "        \n",
    "        self.last = time.time()\n",
    "        last_data = None\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            self.data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            self.frames.append(self.data)\n",
    "            self.rms = audioop.rms(self.data, 2)\n",
    "            \n",
    "            if self.rms > THRESHOLD:\n",
    "                self.last = time.time()\n",
    "\n",
    "            elif (time.time()-self.last > GAP): # Stop recording\n",
    "                print(f\"LAST: {time.time()-self.last}\")\n",
    "                self.stop_time = time.time()\n",
    "                print(f\"{self._name} stops recording...\")\n",
    "                self.is_recording = False\n",
    "                break\n",
    "                \n",
    "                \n",
    "    def transcribe(self):\n",
    "        self.is_transcribing = True\n",
    "        print(f\"{self._name} starts transcribing...\")\n",
    "\n",
    "        global count\n",
    "        count+=1\n",
    "        self.filename = os.path.join(AUDIOFILE_PATH, \"output_\"+str(count)+\".wav\")\n",
    "        \n",
    "        wf = wave.open(self.filename, \"wb\")\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE) \n",
    "        outDat = b\"\".join(self.frames)\n",
    "        del self.frames\n",
    "        wf.writeframes(outDat)\n",
    "        wf.close()\n",
    "        self.text = transcribe(self.filename)\n",
    "        print(f\"File: {self.filename} | Text: {self.text}\")\n",
    "        self.is_transcribing = False\n",
    "        print(f\"{self._name} stops transcribing...\")\n",
    "\n",
    "            \n",
    "    def write(self):\n",
    "        self.is_writing = True\n",
    "        newRow = pd.DataFrame.from_dict(dict(zip(OUTPUT_COLS, [[os.path.abspath(self.filename)], [self.text], [self.start_time], [self.stop_time]])))\n",
    "        with writeLock:\n",
    "            global output_info\n",
    "            output_info = pd.concat([output_info, newRow], ignore_index=True)\n",
    "            output_info.to_csv('session_output.csv')\n",
    "        self.is_writing = False\n",
    "            \n",
    "    def run(self):\n",
    "        self.record()\n",
    "        self.transcribe()\n",
    "        self.write()\n",
    "        self.completed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_recording():\n",
    "    if len(thread_pool):\n",
    "        if any([thread.is_recording for thread in thread_pool]):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_ready():\n",
    "    #speaking = audioop.rms(stream.read(CHUNK, exception_on_overflow=False), 2) > THRESHOLD\n",
    "    recording = check_recording()\n",
    "    has_space = len(thread_pool) < NUM_THREADS\n",
    "    if not recording and has_space:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "Thread-30 starts recording...\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "LAST: 5.034657716751099Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "\n",
      "Thread-30 stops recording...\n",
      "Thread-30 starts transcribing...\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "Thread-30\n",
      "ACTIVE THREADS: 1\n",
      "File: /Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs/output_0.wav | Text: and hope that everything goes...\n",
      "Thread-30 stops transcribing...\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(thread\u001b[38;5;241m.\u001b[39m_name)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACTIVE THREADS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(thread_pool)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m sound \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m rms \u001b[38;5;241m=\u001b[39m audioop\u001b[38;5;241m.\u001b[39mrms(sound, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# this could be an issue here where new threads keep getting recycled...?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/scrap_hack/lib/python3.8/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# init dataframe\n",
    "OUTPUT_COLS = ['audio_path', 'text', 'start', 'stop']\n",
    "NUM_THREADS = 3\n",
    "output_info = pd.DataFrame(columns=OUTPUT_COLS)\n",
    "output_info.to_csv('session_output.csv')\n",
    "overall_start = time.time()\n",
    "\n",
    "writeLock = threading.Lock()\n",
    "\n",
    "#any_recording =  check_recording()\n",
    "\n",
    "thread_pool = []\n",
    "\n",
    "count = -1\n",
    "\n",
    "while time.time() - overall_start < 60 * SESSION_TIME:\n",
    "    thread_pool = [thread for thread in thread_pool if not thread.completed]\n",
    "    for thread in thread_pool:\n",
    "        print(thread._name)\n",
    "    print(f\"ACTIVE THREADS: {len(thread_pool)}\")\n",
    "    sound = stream.read(CHUNK, exception_on_overflow=False)\n",
    "    rms = audioop.rms(sound, 2)\n",
    "    # this could be an issue here where new threads keep getting recycled...?\n",
    "    if rms > THRESHOLD and thread_ready():\n",
    "        new_thread = RecordTranscribe(rms)\n",
    "        thread_pool.append(new_thread)\n",
    "        new_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thread_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = thread_pool[0]\n",
    "for i in a.__dict__.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still talking...\n",
      "LAST: 2.4731838703155518\n",
      "Thread-65 stops recording...\n",
      "Thread-65 starts transcribing...\n",
      "File: /Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs/output_0.wav | Text: to start talking and hopefully things will happen but I'm going to stop talking.\n",
      "Thread-65 stops transcribing...\n",
      "LAST: 2.4723920822143555\n",
      "Thread-67 stops recording...\n",
      "Thread-67 starts transcribing...\n",
      "File: /Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs/output_1.wav | Text: thing Now I keep keep talk talking I starting if I sing if\n",
      "Thread-67 stops transcribing...\n"
     ]
    }
   ],
   "source": [
    "a.rms < THRESHOLD and a.is_recording and (time.time()-a.last > GAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still talking...\n",
      "still talking...\n"
     ]
    }
   ],
   "source": [
    "a.is_recording "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to be restructured so that a new thread only gets instantiated if I start talking again while the previous thread completes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    # checking if the current session is at session time is a high-level step, above the threads. \n",
    "    if time.time() - overall_start > 60*SESSION_TIME:\n",
    "        print(\"Ending session\")\n",
    "        break\n",
    "        \n",
    "        \n",
    "    data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "    rms = audioop.rms(data, 2)  # Calculate Root Mean Square (RMS) volume\n",
    "    if rms > THRESHOLD and not recording:  # Start recording\n",
    "        print(\"Recording started\")\n",
    "        recording = True\n",
    "        last = time.time()\n",
    "    elif rms < THRESHOLD and recording and (time.time()-last > GAP): # Stop recording\n",
    "        count+=1\n",
    "        print(\"Recording stopped\")\n",
    "        recording = False\n",
    "        filename = os.path.join(AUDIOFILE_PATH, \"output_\"+str(count)+\".wav\")\n",
    "        wf = wave.open(filename, \"wb\")\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE) \n",
    "        outDat = b\"\".join(frames)\n",
    "        frames = []\n",
    "        wf.writeframes(outDat)\n",
    "        wf.close()\n",
    "        print(\"Transcribing...\")\n",
    "        text = transcribe(filename)\n",
    "        print(text)\n",
    "        newRow = pd.DataFrame.from_dict(dict(zip(['audio_path', 'text'], [[os.path.abspath(filename)], [text]])))\n",
    "        output_info = pd.concat([output_info, newRow], ignore_index=True)\n",
    "        output_info.to_csv('session_output.csv')\n",
    "        \n",
    "    if recording:\n",
    "        frames.append(data)\n",
    "        if rms > THRESHOLD:\n",
    "            last = time.time()\n",
    "            \n",
    "# Need to add another condition check so that the loop breaks after a given period of time or \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
