{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Live Transcriber\n",
    "This script is for finding the Scarlett and recording audio from it. It will then transcribe the audio and save the text to a csv file in real time.\n",
    "\n",
    "It also implements multithreading so that the recording and transcription can happen simultaneously."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/f004swn/anaconda3/envs/scrap_hack/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import whisper\n",
    "from transcriber import transcribe\n",
    "import threading"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T18:53:34.570276Z",
     "start_time": "2023-09-29T18:53:29.093705Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:15:51.873899Z",
     "start_time": "2023-09-29T19:15:51.839068Z"
    }
   },
   "outputs": [],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "#RATE = 44100\n",
    "RATE = 16000\n",
    "CHUNK = 16000\n",
    "THRESHOLD = 1500  # Adjust this value based on your microphone and environment\n",
    "AUDIOFILE_PATH = '/Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:15:52.534163Z",
     "start_time": "2023-09-29T19:15:52.505342Z"
    }
   },
   "outputs": [],
   "source": [
    "GAP = 2 # Length of silence allowed before cut\n",
    "SESSION_TIME = 3 # number of mins the session can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:17:00.103154Z",
     "start_time": "2023-09-29T19:17:00.085493Z"
    }
   },
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T18:53:44.761925Z",
     "start_time": "2023-09-29T18:53:44.753822Z"
    }
   },
   "outputs": [],
   "source": [
    "#find the Scarlett\n",
    "devices = []\n",
    "device_index = None\n",
    "for i in range(p.get_device_count()):\n",
    "    device_info = p.get_device_info_by_index(i)\n",
    "    devices.append(device_info)\n",
    "    if \"Scarlett\" in device_info[\"name\"] and device_info[\"maxInputChannels\"] > 0:\n",
    "        device_index = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#find the Scarlett\n",
    "devices = []\n",
    "device_index = None\n",
    "for i in range(p.get_device_count()):\n",
    "    device_info = p.get_device_info_by_index(i)\n",
    "    devices.append(device_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T19:17:24.424780Z",
     "start_time": "2023-09-29T19:17:24.407673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{'index': 4,\n 'structVersion': 2,\n 'name': 'MacBook Pro Microphone',\n 'hostApi': 0,\n 'maxInputChannels': 1,\n 'maxOutputChannels': 0,\n 'defaultLowInputLatency': 0.034520833333333334,\n 'defaultLowOutputLatency': 0.01,\n 'defaultHighInputLatency': 0.043854166666666666,\n 'defaultHighOutputLatency': 0.1,\n 'defaultSampleRate': 48000.0}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_device_info_by_index(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T19:21:18.428819Z",
     "start_time": "2023-09-29T19:21:18.414104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:17:03.459282Z",
     "start_time": "2023-09-29T19:17:03.416845Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno -9998] Invalid number of channels",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m stream \u001B[38;5;241m=\u001B[39m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_device_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFORMAT\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                \u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCHANNELS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRATE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                \u001B[49m\u001B[43mframes_per_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCHUNK\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/scrap_hack/lib/python3.8/site-packages/pyaudio/__init__.py:639\u001B[0m, in \u001B[0;36mPyAudio.open\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;124;03m\"\"\"Opens a new stream.\u001B[39;00m\n\u001B[1;32m    633\u001B[0m \n\u001B[1;32m    634\u001B[0m \u001B[38;5;124;03m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    637\u001B[0m \u001B[38;5;124;03m    :returns: A new :py:class:`PyAudio.Stream`\u001B[39;00m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 639\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[43mPyAudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    640\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streams\u001B[38;5;241m.\u001B[39madd(stream)\n\u001B[1;32m    641\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m stream\n",
      "File \u001B[0;32m~/anaconda3/envs/scrap_hack/lib/python3.8/site-packages/pyaudio/__init__.py:441\u001B[0m, in \u001B[0;36mPyAudio.Stream.__init__\u001B[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001B[0m\n\u001B[1;32m    438\u001B[0m     arguments[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstream_callback\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m stream_callback\n\u001B[1;32m    440\u001B[0m \u001B[38;5;66;03m# calling pa.open returns a stream object\u001B[39;00m\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream \u001B[38;5;241m=\u001B[39m \u001B[43mpa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43marguments\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_latency \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream\u001B[38;5;241m.\u001B[39minputLatency\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_latency \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream\u001B[38;5;241m.\u001B[39moutputLatency\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno -9998] Invalid number of channels"
     ]
    }
   ],
   "source": [
    "# stream = p.open(input_device_index=device_index,\n",
    "#                 format=FORMAT,\n",
    "#                 channels=CHANNELS,\n",
    "#                 rate=RATE,\n",
    "#                 input=True,\n",
    "#                 frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "stream = p.open(input_device_index=4,\n",
    "                format=FORMAT,\n",
    "                channels=1,\n",
    "                rate=16000,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T19:23:17.056811Z",
     "start_time": "2023-09-29T19:23:17.034562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:23:18.626953Z",
     "start_time": "2023-09-29T19:23:18.614910Z"
    }
   },
   "outputs": [],
   "source": [
    "class RecordTranscribe(threading.Thread):\n",
    "    def __init__(self, rms):\n",
    "        super().__init__()\n",
    "        self.is_recording = True\n",
    "        self.is_transcribing = False\n",
    "        self.is_writing = False\n",
    "        self.rms = rms\n",
    "        self.text = None\n",
    "        self.start_time = None\n",
    "        self.stop_time = None\n",
    "        self.frames = []\n",
    "        self.data = None\n",
    "        self.completed = False\n",
    "        \n",
    "    def record(self):\n",
    "        self.start_time = time.time()\n",
    "        print(f\"{self._name} starts recording...\")\n",
    "        \n",
    "        self.last = time.time()\n",
    "        last_data = None\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            self.data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            self.frames.append(self.data)\n",
    "            self.rms = audioop.rms(self.data, 2)\n",
    "            \n",
    "            if self.rms > THRESHOLD:\n",
    "                self.last = time.time()\n",
    "\n",
    "            elif (time.time()-self.last > GAP): # Stop recording\n",
    "                print(f\"LAST: {time.time()-self.last}\")\n",
    "                self.stop_time = time.time()\n",
    "                print(f\"{self._name} stops recording...\")\n",
    "                self.is_recording = False\n",
    "                break\n",
    "                \n",
    "                \n",
    "    def transcribe(self):\n",
    "        self.is_transcribing = True\n",
    "        print(f\"{self._name} starts transcribing...\")\n",
    "\n",
    "        global count\n",
    "        count+=1\n",
    "        self.filename = os.path.join(AUDIOFILE_PATH, \"output_\"+str(count)+\".wav\")\n",
    "        \n",
    "        wf = wave.open(self.filename, \"wb\")\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE) \n",
    "        outDat = b\"\".join(self.frames)\n",
    "        del self.frames\n",
    "        wf.writeframes(outDat)\n",
    "        wf.close()\n",
    "        self.text = transcribe(self.filename)\n",
    "        print(f\"File: {self.filename} | Text: {self.text}\")\n",
    "        self.is_transcribing = False\n",
    "        print(f\"{self._name} stops transcribing...\")\n",
    "\n",
    "            \n",
    "    def write(self):\n",
    "        self.is_writing = True\n",
    "        newRow = pd.DataFrame.from_dict(dict(zip(OUTPUT_COLS, [[os.path.abspath(self.filename)], [self.text], [self.start_time], [self.stop_time]])))\n",
    "        with writeLock:\n",
    "            global output_info\n",
    "            output_info = pd.concat([output_info, newRow], ignore_index=True)\n",
    "            output_info.to_csv('session_output.csv')\n",
    "        self.is_writing = False\n",
    "            \n",
    "    def run(self):\n",
    "        self.record()\n",
    "        self.transcribe()\n",
    "        self.write()\n",
    "        self.completed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:23:18.819139Z",
     "start_time": "2023-09-29T19:23:18.793069Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_recording():\n",
    "    if len(thread_pool):\n",
    "        if any([thread.is_recording for thread in thread_pool]):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:23:19.041631Z",
     "start_time": "2023-09-29T19:23:19.025650Z"
    }
   },
   "outputs": [],
   "source": [
    "def thread_ready():\n",
    "    #speaking = audioop.rms(stream.read(CHUNK, exception_on_overflow=False), 2) > THRESHOLD\n",
    "    recording = check_recording()\n",
    "    has_space = len(thread_pool) < NUM_THREADS\n",
    "    if not recording and has_space:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-29T19:23:19.048461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "Thread-6 starts recording...Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "LAST: 2.9806721210479736\n",
      "Thread-6 stops recording...\n",
      "Thread-6 starts transcribing...\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "Thread-6\n",
      "ACTIVE THREADS: 1\n",
      "File: /Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs/output_0.wav | Text: Custom, custom, custom, custom, custom, custom, custom.\n",
      "Thread-6 stops transcribing...\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n",
      "ACTIVE THREADS: 0\n"
     ]
    }
   ],
   "source": [
    "# init dataframe\n",
    "OUTPUT_COLS = ['audio_path', 'text', 'start', 'stop']\n",
    "NUM_THREADS = 3\n",
    "output_info = pd.DataFrame(columns=OUTPUT_COLS)\n",
    "output_info.to_csv('session_output.csv')\n",
    "overall_start = time.time()\n",
    "\n",
    "writeLock = threading.Lock()\n",
    "\n",
    "#any_recording =  check_recording()\n",
    "\n",
    "thread_pool = []\n",
    "\n",
    "count = -1\n",
    "\n",
    "while time.time() - overall_start < 60 * SESSION_TIME:\n",
    "    thread_pool = [thread for thread in thread_pool if not thread.completed]\n",
    "    for thread in thread_pool:\n",
    "        print(thread._name)    \n",
    "    print(f\"ACTIVE THREADS: {len(thread_pool)}\")\n",
    "    \n",
    "    sound = stream.read(CHUNK, exception_on_overflow=False)\n",
    "    rms = audioop.rms(sound, 2)\n",
    "    # this could be an issue here where new threads keep getting recycled...?\n",
    "    if rms > THRESHOLD and thread_ready():\n",
    "        new_thread = RecordTranscribe(rms)\n",
    "        thread_pool.append(new_thread)\n",
    "        new_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thread_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = thread_pool[0]\n",
    "for i in a.__dict__.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still talking...\n",
      "LAST: 2.4731838703155518\n",
      "Thread-65 stops recording...\n",
      "Thread-65 starts transcribing...\n",
      "File: /Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs/output_0.wav | Text: to start talking and hopefully things will happen but I'm going to stop talking.\n",
      "Thread-65 stops transcribing...\n",
      "LAST: 2.4723920822143555\n",
      "Thread-67 stops recording...\n",
      "Thread-67 starts transcribing...\n",
      "File: /Users/f004swn/Dropbox (Dartmouth College)/scrap_hack/ArtsIntegrationHack/scripts/audio_outputs/output_1.wav | Text: thing Now I keep keep talk talking I starting if I sing if\n",
      "Thread-67 stops transcribing...\n"
     ]
    }
   ],
   "source": [
    "a.rms < THRESHOLD and a.is_recording and (time.time()-a.last > GAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still talking...\n",
      "still talking...\n"
     ]
    }
   ],
   "source": [
    "a.is_recording "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to be restructured so that a new thread only gets instantiated if I start talking again while the previous thread completes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    # checking if the current session is at session time is a high-level step, above the threads. \n",
    "    if time.time() - overall_start > 60*SESSION_TIME:\n",
    "        print(\"Ending session\")\n",
    "        break\n",
    "        \n",
    "        \n",
    "    data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "    rms = audioop.rms(data, 2)  # Calculate Root Mean Square (RMS) volume\n",
    "    if rms > THRESHOLD and not recording:  # Start recording\n",
    "        print(\"Recording started\")\n",
    "        recording = True\n",
    "        last = time.time()\n",
    "    elif rms < THRESHOLD and recording and (time.time()-last > GAP): # Stop recording\n",
    "        count+=1\n",
    "        print(\"Recording stopped\")\n",
    "        recording = False\n",
    "        filename = os.path.join(AUDIOFILE_PATH, \"output_\"+str(count)+\".wav\")\n",
    "        wf = wave.open(filename, \"wb\")\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE) \n",
    "        outDat = b\"\".join(frames)\n",
    "        frames = []\n",
    "        wf.writeframes(outDat)\n",
    "        wf.close()\n",
    "        print(\"Transcribing...\")\n",
    "        text = transcribe(filename)\n",
    "        print(text)\n",
    "        newRow = pd.DataFrame.from_dict(dict(zip(['audio_path', 'text'], [[os.path.abspath(filename)], [text]])))\n",
    "        output_info = pd.concat([output_info, newRow], ignore_index=True)\n",
    "        output_info.to_csv('session_output.csv')\n",
    "        \n",
    "    if recording:\n",
    "        frames.append(data)\n",
    "        if rms > THRESHOLD:\n",
    "            last = time.time()\n",
    "            \n",
    "# Need to add another condition check so that the loop breaks after a given period of time or \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
